이 글은 MLOps의 개념과 장단점, 실제 기업 활용 사례를 소개하며, ML 생애주기를 어떻게 체계화하고 자동화하는지 설명한다. MLflow, Kubeflow, Airflow 등 주요 도구를 비교하고, 단계별로 MLOps를 구축하는 방법과 툴 선택 가이드도 함께 제공한다.


# MLOps란?

**MLOps (Machine Learning + Operations)** 는 기계 학습(ML) 모델을 **효율적으로 개발, 배포, 운영**하기 위한 **방법론 또는 시스템을 의미한다.**

> **즉, ML 모델을 만들고, 테스트하고, 실제 서비스에 잘 적용되도록 돕는 전체 프로세스를 관리하는 방법**
> 
> 
> **>> 머신러닝의 생애주기를 자동화하고 체계화하기 위한 방법론**
> 

### MLOps의 장점

1. **빠른 모델 배포**
    - 모델을 개발하자마자 자동으로 배포 가능 (예: CI/CD 파이프라인처럼 동작)
2. **버전 관리**
    - 코드뿐 아니라 **데이터, 모델, 실험 결과**도 버전별로 관리 가
3. **재현 가능성**
    - “이 모델은 왜 잘 됐지?”를 다시 확인하고 실험을 **재현 가능**
4. **모델 모니터링 및 자동화**
    - 성능 저하를 감지하면 자동으로 다시 훈련시키거나 경고 생성 가능
5. **협업 용이**
    - 개발자, 데이터 사이언티스트, DevOps 엔지니어 간 **협업이 체계화됨**

### MLOps의 단점

1. **초기 구축 비용/시간이 큼**
    - 자동화 파이프라인, 실험 관리 시스템, 모니터링 등 인프라가 필요함
2. **복잡한 툴 조합**
    - MLflow, Kubeflow, Airflow, Seldon, Docker, Kubernetes 등등 배워야 할 도구가 비교적 많음

### MLOps가 사용되는 분야 & 필요성

- **금융**
    
    → 고객 부정 행위 탐지 모델을 실시간으로 운영해야 함.
    
- **헬스케어**
    
    → 환자 예측 모델의 정확도 저하 여부를 지속적으로 모니터링해야 함.
    
- **이커머스**
    
    → 추천 알고리즘을 계속해서 실험하고 A/B 테스트해야 함.
    
- **자율주행**
    
    → 모델이 실제 환경에서 어떻게 반응하는지를 **지속적으로 트래킹하고 업데이트**해야 함.
    

> 📌 **왜 필요할까?**
> 
> → 머신러닝 모델은 단순한 코드가 아니기 때문에
> **데이터, 실험, 배포, 모니터링**까지 전 과정을 체계화하지 않으면 **실제 서비스에 적용하기 어려움**.

### 실제 기업 사례

1. **Netflix**
    - 사용자 추천 시스템의 실험, 배포, 성능 모니터링을 MLOps로 관리
    - 다양한 추천 모델을 A/B 테스트하고, 결과 기반으로 자동 업데이트
2. **Airbnb**
    - 가격 예측, 사기 탐지 모델을 MLflow로 추적하고 자동 배포
3. **Uber**
    - Michelangelo라는 자체 MLOps 플랫폼을 사용해 수많은 모델을 관리
    - 데이터 수집부터 실시간 추론까지 완전 자동화

### 헷갈렸던 점

1. **MLOps는 DevOps와는 다른 것임**
    - DevOps는 코드 중심, MLOps는 **데이터 중심**
    - 데이터와 모델이 계속 바뀌기 때문에 **모델 성능이 언제든 떨어질 수 있음 → 모니터링 필수!**
2. **MLOps는 자체로 도구가 아니라 “문화”**
    - 단순히 툴을 배우는 게 아니라, **효율적인 실험, 협업, 반복, 운영 문화를 만드는 것 위주**
3. **작게 시작하고 점점 확장하자**
    - 처음부터 완벽한 MLOps 시스템을 만들기보단, 실험 관리부터 시작해서, 배포 자동화, 모니터링 순으로 **조금씩 확장**하는 게 비교적 편함

## MLOps 사용 툴

클라우드 활용하면 효과 극대화되는 느낌 !! (조금 더 알아보니 이거는 개인 프로젝트 등에서 공부하기 좋은 용도)

- SageMaker, Vertex AI는 MLOps 시스템을 기본 제공

### MLOps에서 가장 많이 쓰이는 도구들

| 구분 | 대표 도구 | 설명 |
| --- | --- | --- |
| **실험 추적** | `MLflow`, `Weights & Biases` | 모델 성능, 파라미터, 메트릭, 버전 등을 관리함 |
| **데이터/모델 버전 관리** | `DVC`, `Git` | 데이터, 모델 파일을 Git처럼 버전 관리함 |
| **워크플로우 스케줄링** | `Airflow`, `Prefect` | 파이프라인 실행 순서를 정의하고 자동화함 |
| **모델 배포** | `Docker`, `Kubernetes`, `Seldon`, `KServe` | 컨테이너화 및 자동 배포/스케일링 환경 구축에 사용함 |
| **모델 서빙 (API화)** | `FastAPI`, `Flask`, `TorchServe` | 모델을 REST API로 만들어 추론 요청을 받을 수 있게 함 |
| **모델 모니터링** | `Prometheus`, `Grafana`, `Evidently AI` | 운영 중인 모델의 성능을 실시간 모니터링함 |
| **전체 파이프라인 자동화** | `Kubeflow`, `SageMaker`, `Vertex AI` | MLOps 전 과정을 통합 관리함 |
- MLOps에서 모든 도구를 한 번에 쓰는 것은 비효율적임.
- **MLflow, Docker, Git**은 거의 모든 환경에서 기본적으로 쓰임.
- **Airflow, DVC, Kubernetes**는 프로젝트가 커지면 자연스럽게 필요해짐.
    - 데이터 버전 관리 (DVC)는 꼭 챙겨라! (코드보다 데이터가 더 중요해지는 시대니까)
- 통합 솔루션(Kubeflow, SageMaker 등)은 **리소스가 충분할 때** 도입하면 좋음.

### 초기 MLOps 구축 시, 필수로 써야 하는 도구

처음 MLOps를 구축한다면 아래 5가지는 사실상 **기본 구성요소**라 볼 수 있음.

| 목적 | 필수 도구 | 이유 |
| --- | --- | --- |
| 모델 실험 기록 | ✅ `MLflow` | 실험 결과를 체계적으로 저장/관리함 |
| 모델 버전 관리 | ✅ `Git`, `DVC` | 모델, 데이터, 코드를 함께 버전 관리함 |
| 모델 패키징 | ✅ `Docker` | 모델을 어디서든 실행 가능하도록 만듦 |
| 자동 배포 | ✅ `Kubernetes` | 확장성과 안정적인 운영을 보장함 |
| 파이프라인 구성 | ✅ `Airflow` | 작업 순서를 자동화하고 주기적으로 실행 가능함 |

> 이 외 도구는 프로젝트의 규모와 복잡도에 따라 점진적으로 추가하면 됨.
> 

- 추가적으로 궁금해서 알아본 것들 (일반적으로 상황에 따라 어떻게 도구들을 사용하는지)
    
    1. **개인 or 연구용 프로젝트**
    
    - `MLflow` + `Git` + `Docker`
        
        → 실험 관리 + 모델 저장 + 컨테이너화만으로 충분함
        
    
    2. **스타트업/소규모 서비스**
    
    - `MLflow` + `DVC` + `Airflow` + `Docker` + `Kubernetes(SKAFFOLD)`
        
        → 파이프라인 자동화, 재현성, 배포까지 확보함
        
    
    3. **엔터프라이즈/대규모**
    
    - `Kubeflow` or `SageMaker`, + 위 도구 전반
        
        → 통합 플랫폼 기반으로 모든 것을 관리함
        
    

### MLflow, Kubeflow란?

**[ MLflow란? ]**

- **실험 추적, 모델 저장, 배포까지** 간단하게 도와주는 도구
- 주요 기능:
    - `Tracking`: 실험 결과(파라미터, 정확도 등) 기록
    - `Projects`: 코드 패키징
    - `Models`: 모델 저장 및 배포
    - `Registry`: 모델 버전 관리

➡️ 내가 어떤 하이퍼파라미터로 어떤 성능이 나왔는지 자동 기록해주고, 모델도 저장해주는 “노트북 + 도구 모음”

**[ Kubeflow란? ]**

- **머신러닝 전체 파이프라인을 Kubernetes 위에서 자동화**
- 주요 기능:
    - 파이프라인 정의 (TFX 등 사용 가능)
    - 모델 학습 자동화
    - 배포, 모니터링, 재학습 자동화

➡️ 대기업이나 큰 플랫폼에서 “데이터 수집부터 모델 운영까지 전부 자동화”하는 데 쓰는 종합 솔루션

**[ MLflow vs Kubeflow 비교 ]**

| 항목 | MLflow | Kubeflow |
| --- | --- | --- |
| **목적** | 머신러닝 실험 관리 중심 | 머신러닝 파이프라인 전체 자동화 |
| **주요 기능** | 실험 추적, 모델 저장, 배포 | 워크플로우 관리, 모델 훈련/배포, 모니터링 등 전체 파이프라인 |
| **학습 곡선** | 쉬움 (빠르게 시작 가능) | 어렵고 복잡함 (Kubernetes 기반 이해 필요) |
| **도입 난이도** | 로컬, 클라우드 모두 가능 / 가벼움 | Kubernetes 환경 필요 / 설정 복잡 |
| **추천 대상** | 실험 위주로 작업하는 소규모 팀 | 대규모 서비스화/자동화가 필요한 기업 |

## MLOps 생애주기

MLOps 생애주기는  **Machine Learning의 생애주기를 따라감**

**[ Machine Learning의 생애주기 ]**

![liefcycle](images/post13/image-1.png)

![mlops](images/post13/image-2.png)

1. **데이터 수집 & 전처리**
    - 데이터셋을 수집하고 전처리 및 정제 작업을 수행함
        - 이상치 제거, 결측값 처리, 피처 엔지니어링 등을 포함함
    - ETL 도구나 스케줄러(Airflow 등)로 수집 자동화
        - 주로 `Pandas`, `Spark`, `Airflow` 등을 사용함
2. **데이터 버전 관리**
    - 사용한 데이터셋의 버전을 관리함
    - 모델 재현을 위해 어떤 데이터로 학습했는지 기록해야 함
    - `DVC` 또는 `LakeFS`, `Delta Lake` 등의 도구를 사용함
3. **모델 훈련**
    - 다양한 알고리즘, 하이퍼파라미터로 모델을 실험함
    - 각 실험의 성능, 사용된 데이터/코드를 추적함
    - `MLflow`, `Weights & Biases`, `Comet ML` 등이 사용됨
4. **모델 평가 및 선택**
    - 테스트셋을 기반으로 성능을 평가하고 최적 모델(혹은 버전)을 선택함
        - 모델 검증에는 ROC, F1 score, A/B 테스트 등이 활용됨
5. **모델 배포**
    - API 형태로 Docker/Kubernetes에 배포
    - Seldon, KServe, SageMaker 등 사용
6. **모니터링**
    - 운영 중인 모델의 예측 성능을 지속적으로 모니터링함
    - 데이터 드리프트, 모델 드리프트 발생 여부를 탐지함 >> 자동 재훈련 트리거
    - `Prometheus`, `Grafana`, `Evidently AI` 등을 사용함
    > 데이터 드리프트(Data Drift), 모델 드리프트(Model Drift)란?
    >    
    >    **[ 데이터 드리프트(Data Drift) ]** 
    >    
    >    - 훈련할 때 사용한 데이터와, 실제 서비스 중에 들어오는 데이터의 분포가 달라지는 현상
    >        - 모델이 **익숙하지 않은 데이터**를 받으므로 예측 성능이 하락함
    >    
    >    (예) 
    >    
    >    - 모델 학습 당시에는 남성/여성 비율이 5:5였는데,
    >        
    >        최근에는 사용자 중 80%가 여성으로 바뀌었을 경우 → **입력 데이터가 바뀐 것**
    >        
    >    - 텍스트 모델의 경우, 유행어, 신조어 등이 등장해 단어 사용 패턴이 바뀜
    > <br/> 
    > 
    > **[ 모델 드리프트(Model Drift) ]**
    

7. **재학습**
    - 성능 저하나 데이터 환경 변화에 대응하여 주기적으로 모델을 재학습함
    - 이 과정을 **Feedback Loop** 또는 **Continuous Training**이라고 함
    - 모니터링 결과를 트리거로 자동 훈련을 구성할 수도 있음 (ex. `Airflow`, `Kubeflow Pipelines`)

## MLOps 구축

단계별 구축 설명으로, 꼭 이렇게 하지 않아도 되긴 함.

**1. 실험 추적부터 (MLflow)**

- 실험 기록 자동화 (하이퍼파라미터, 정확도)
- 모델 저장 및 버전 관리
- 로컬 or S3에 모델 아티팩트 저장

```python
import mlflow

with mlflow.start_run():
    mlflow.log_param("lr", 0.01)
    mlflow.log_metric("accuracy", 0.94)
    mlflow.sklearn.log_model(model, "model")
```

**2. 훈련 파이프라인 구성 (with Airflow, Prefect)**

- 데이터 수집 → 전처리 → 훈련까지 파이프라인 자동화
- 매일 특정 시간에 실행되도록 예약 가능

**3. 모델 배포 자동화**

- 모델을 Docker 이미지로 만들고, Kubernetes, Seldon, KServe 등으로 배포

```bash
# Dockerfile 예시
FROM python:3.9
COPY model.pkl /app/model.pkl
CMD ["python", "serve.py"]
```

**4. 모니터링 & 자동 재훈련**

- Prometheus, Grafana로 지표 시각화
- 데이터 드리프트 감지되면 → 자동 재훈련 트리거